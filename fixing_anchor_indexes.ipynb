{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 50x50 grid filled with zeros (black)\n",
    "grid = np.zeros((50, 50))\n",
    "\n",
    "# Set a couple of white elements by specifying their positions\n",
    "# For example, let's set the element at row 10, column 20 and row 30, column 40 to white.\n",
    "grid[4, 4] = 1  # White\n",
    "grid[44, 4] = 1  # White\n",
    "grid[20, 44] = 1  # White\n",
    "\n",
    "# Display the grid\n",
    "plt.imshow(grid, cmap='gray', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/net/travail/jpenatrapero/results/results_3_3_imagenet_original.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juanm\\Documents\\IPCV_3\\TRDP\\OODbench\\finding_index_test.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juanm/Documents/IPCV_3/TRDP/OODbench/finding_index_test.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolors\u001b[39;00m \u001b[39mimport\u001b[39;00m ListedColormap, BoundaryNorm\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juanm/Documents/IPCV_3/TRDP/OODbench/finding_index_test.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m path_results \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/net/travail/jpenatrapero/results/results_3_3_imagenet_original.pkl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juanm/Documents/IPCV_3/TRDP/OODbench/finding_index_test.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path_results, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juanm/Documents/IPCV_3/TRDP/OODbench/finding_index_test.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     data \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juanm/Documents/IPCV_3/TRDP/OODbench/finding_index_test.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Read the class labels from the file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\juanm\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/net/travail/jpenatrapero/results/results_3_3_imagenet_original.pkl'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "path_results = '/net/travail/jpenatrapero/results/results_3_3_imagenet_original.pkl'\n",
    "with open(path_results, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Read the class labels from the file\n",
    "with open('imagenet1klabels.txt', 'r') as file:\n",
    "    class_labels_dict = eval(file.read())\n",
    "# List the keys in the dictionary\n",
    "keys = data.keys()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an image (replace this with your matrix)\n",
    "matrix = data['Matrix_0']  # Your 50x50 matrix of class labels\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes is not None:\n",
    "        x, y = int(event.xdata), int(event.ydata)\n",
    "        value = matrix[y, x]\n",
    "        ax.set_title(f'Value at ({x}, {y}): {value}')\n",
    "# Create a sample 50x50 matrix (you can use your own data)\n",
    "\n",
    "# Define a colormap for different colors\n",
    "cmap = plt.get_cmap('viridis')  # You can choose a different colormap\n",
    "\n",
    "# Create a figure and axis for the plot\n",
    "fig, ax = plt.subplots()\n",
    "# Plot asterisk, triangle, and square\n",
    "ax.plot(4, 4, marker='*', markersize=10, color='red', markeredgecolor='black')\n",
    "ax.plot(44, 4, marker='^', markersize=10, color='blue', markeredgecolor='black')\n",
    "ax.plot(20, 44, marker='s', markersize=10, color='green', markeredgecolor='black')\n",
    "\n",
    "\n",
    "# Plot the matrix as an image with colors\n",
    "img = ax.imshow(matrix, cmap=cmap)\n",
    "\n",
    "# Add a colorbar for reference\n",
    "cbar = plt.colorbar(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Connect the click event to the function\n",
    "fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# Display the figure with interactivity\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\juanm\\anaconda3\\envs\\torch\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\juanm\\anaconda3\\envs\\torch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from model import get_model\n",
    "from data import get_data, make_planeloader\n",
    "from utils import get_loss_function, get_scheduler, get_random_images, produce_plot, get_noisy_images, AttackPGD\n",
    "from evaluation import train, test, test_on_trainset, decision_boundary, test_on_adv\n",
    "from options import options\n",
    "from utils import simple_lapsed_time\n",
    "from myFunctions import *\n",
    "from utils import produce_plot_sepleg_IMAGENET #TODO : fix representation of images\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA IS AVALIABLE $.$ \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Important Note! -> Change the model loading in the intialization\n",
    "load_net = '/net/travail/jpenatrapero/dbViz/pretrained_models/resnet18-5c106cde.pth'\n",
    "net_name = 'resnet' \n",
    "set_seed = 777\n",
    "set_data_seed = 1\n",
    "save_net = 'saves'\n",
    "imgs = 600,4000,1600\n",
    "epochs = 2\n",
    "lr = 0.01\n",
    "resolution = 50 #Default is 500 and it takes 3 mins\n",
    "batch_size_planeloader = 1\n",
    "saveplot = False\n",
    "num_classes = 3\n",
    "num_images_experiment = 3\n",
    "idx_pred_im = [11,81,68]#Fixed values with the indexes corresponding \n",
    "#to our original images in the format of the vector pred\n",
    "# the class_pred[idx_pred_im[1]] is the predicted class for the first imae of the triplet\n",
    "\n",
    "c1= \"n02106662\" #German shepard\n",
    "c2= \"n03388043\" #Fountain\n",
    "c3= \"n03594945\" #Jeep\n",
    "#Labesl of the imagenet\n",
    "labels = ['German_shepherd','fountain','jeep']\n",
    "ground_truth_im = [235,562,609]\n",
    "\n",
    "#Saving the results\n",
    "results_folder = \"results\"\n",
    "model_name = 'resnet50' #Name of the model for saved data\n",
    "\n",
    "# Log of the results\n",
    "active_log = False\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA IS AVALIABLE $.$ \")\n",
    "else:\n",
    "    print(\"No cuda avaliable :´( \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the network or loading the network\n",
      "Time taken to load the model: 00:00:00.27\n"
     ]
    }
   ],
   "source": [
    "# Data/other training stuff\n",
    "import torchvision.models as models\n",
    "torch.manual_seed(set_data_seed)\n",
    "torch.manual_seed(set_seed)\n",
    "test_accs = []\n",
    "train_accs = []\n",
    "\n",
    "\n",
    "# Train or load base network\n",
    "print(\"Training the network or loading the network\")\n",
    "\n",
    "start = time.time()\n",
    "best_acc = 0  # best test accuracy\n",
    "best_epoch = 0\n",
    "\n",
    "\n",
    "#########################################################\n",
    "#   LOADING THE NETWORK\n",
    "#########################################################\n",
    "net = models.resnet18(pretrained=True)\n",
    "net.load_state_dict(torch.load(load_net))\n",
    "    \n",
    "\n",
    "# test_acc, predicted = test(args, net, testloader, device)\n",
    "# print(test_acc)\n",
    "end = time.time()\n",
    "simple_lapsed_time(\"Time taken to load the model\", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############  DATASET   #################\n",
    "imgs = 'imagenet'\n",
    "start = time.time()\n",
    "if imgs is None:\n",
    "    print(\"imgs is None -> You need to provide the images to load\")\n",
    "\n",
    "elif imgs == 'handcrafted':\n",
    "    path_to_db= \"OODatasets/handcrafted/\"\n",
    "    imgCombinationsTensor, filenames_combinations = getCombiFromDB(c1, c2, c3,path_to_db)\n",
    "\n",
    "elif imgs == 'signal':\n",
    "    path_to_db= \"OODatasets/signal/\"\n",
    "    imgCombinationsTensor, filenames_combinations = getCombiFromDB(c1, c2, c3,path_to_db)\n",
    "\n",
    "elif imgs == 'generated':\n",
    "    path_to_db= \"OODatasets/generated/\"\n",
    "    imgCombinationsTensor, filenames_combinations = getCombiFromDB(c1, c2, c3,path_to_db)\n",
    "\n",
    "elif imgs == 'imagenet':\n",
    "    path_to_db= \"OODatasets/imagenet_val_resized/\"\n",
    "    imgCombinationsTensor, filenames_combinations = getCombiFromDB(c1, c2, c3,path_to_db)\n",
    "\n",
    "elif imgs == 'test10images':\n",
    "    path_to_db= \"/net/cremi/jpenatrapero/DATASETS/10images/\"\n",
    "    imgCombinationsTensor, filenames_combinations = getCombiFromDB(c1, c2, c3,path_to_db)\n",
    "else:\n",
    "    print('UNRECOGNICED image dataset')\n",
    "\n",
    "sampleids = '_'.join(list(map(str,labels)))\n",
    "\n",
    "n_combis = num_images_experiment**num_classes\n",
    "\n",
    "accuracy_triplet = []\n",
    "margin_triplet = []\n",
    "results_all_pred = {}  # Initialize an empty dictionary to store pred matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = types.SimpleNamespace()\n",
    "arg.net = net_name\n",
    "arg.batch_size_planeloader = batch_size_planeloader\n",
    "arg.resolution = 50\n",
    "arg.bs = 128\n",
    "arg.baseset = \"CIFAR10\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args['resolution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Starting loop through all triplet combinations..\n",
      "Progress: 3.70% complete\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'resolution'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/cache-jpenatrapero/ipykernel_40696/4062835177.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Creating planeloader for the image space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplaneloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_planeloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#Using the model to predict all the plane\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaneloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/autofs/unityaccount/cremi/jpenatrapero/TRDP/OODbench/data.py\u001b[0m in \u001b[0;36mmake_planeloader\u001b[0;34m(images, args)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_orthog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_plane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mplaneset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplane_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_orthog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_l\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'resolution'"
     ]
    }
   ],
   "source": [
    "print('==> Starting loop through all triplet combinations..')\n",
    "for i_triplet in range(n_combis):\n",
    "\n",
    "    progress = (i_triplet + 1) / n_combis * 100\n",
    "    print(f\"Progress: {progress:.2f}% complete\", end=\"\\r\", flush=True)\n",
    "\n",
    "    images = imgCombinationsTensor[i_triplet]\n",
    "\n",
    "    #Creating planeloader for the image space\n",
    "    planeloader = make_planeloader(images, args)\n",
    "    #Using the model to predict all the plane\n",
    "    preds = decision_boundary(args, net, planeloader, device)\n",
    "\n",
    "    #Getting the labels of the predictions\n",
    "    preds = torch.stack((preds))\n",
    "    temp=0.01 #Not sure what this does\n",
    "    preds = nn.Softmax(dim=1)(preds / temp)\n",
    "    class_vect = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "\n",
    "    #Converting vector to matrix\n",
    "    pred_matrix  = np.reshape(class_vect, (resolution, resolution))\n",
    "\n",
    "    results_all_pred[f\"Matrix_{i_triplet}\"] = pred_matrix\n",
    "    results_all_pred[f\"Combi_{i_triplet}\"] = filenames_combinations[i_triplet]\n",
    "\n",
    "    #accuracy_triplet, margin_triplet = margin_TRDP_I (class_pred,pred_matrix,idx_pred_im,ground_truth_im,accuracy_triplet,margin_triplet)\n",
    "\n",
    "\n",
    "############# END OF FOR LOOP TRHOUGH ALL THE TRIPLETS\n",
    "\n",
    "end = time.time()\n",
    "simple_lapsed_time(\"Time taken for all combinatios of triplets\", end-start)\n",
    "# Calculate average margins for accurate predictions\n",
    "\n",
    "\n",
    "save_results('/net/travail/jpenatrapero/results',results_all_pred,\"results_3_3_imagenet_original.pkl\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbviz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
